{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1D1yc_V2oRW90x38_VYjRSbUI0xboOcJE",
      "authorship_tag": "ABX9TyPt4So0pboOWyYWYXDPTkES",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcusflygar1-hash/AH2179_Project/blob/main/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "yO-vUlw1yKh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okey-\n",
        "\n",
        "\n",
        "\n",
        "Psuedo Kod.\n",
        "rensa och \"clean\" datan. Ta bort all null values och NaN's.\n",
        "\n",
        "Dela sedan upp i 5 minuters tidsperioder.\n",
        "\n"
      ],
      "metadata": {
        "id": "3hWYm91cq5I9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the data and cleaning etc."
      ],
      "metadata": {
        "id": "LHVSQYKfLwaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tds = pd.read_csv('training_dataset.csv', sep=';')\n",
        "ev_ds = pd.read_csv('evaluation_dataset.csv',sep=';')\n",
        "f_ev_ds = pd.read_csv('final_evaluation_dataset.csv', sep=';')\n"
      ],
      "metadata": {
        "id": "-rVQM72Kq4ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure Date is a string before concatenating\n",
        "tds[\"Date\"] = tds[\"Date\"].astype(str)\n",
        "\n",
        "# Combine Date and Time into a single datetime column\n",
        "tds[\"datetime\"] = pd.to_datetime(tds[\"Date\"] + \" \" + tds[\"Time\"])\n",
        "\n",
        "# Plot speed vs datetime\n",
        "tds.plot(x=\"datetime\", y=\"SPEED_MS_AVG\", kind=\"line\", figsize=(12,6))\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Average Speed (m/s)\")\n",
        "plt.title(\"Speed over Time\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g7POCe75Oj_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tds.plot(x='datetime', y='FLOW', kind='line', figsize=(20,14))\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Flow')\n",
        "plt.title('Flow over Time')"
      ],
      "metadata": {
        "id": "A9C4Xqt_PtVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n training dataset')\n",
        "print(tds.head())\n",
        "print('\\n evaluation dataset------------')\n",
        "print(ev_ds.head())\n",
        "print('\\n final evaluation dataset --------')\n",
        "print(f_ev_ds.head())"
      ],
      "metadata": {
        "id": "ed8Fuwk6KpPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training dataset')\n",
        "print(tds.isna().sum())\n",
        "print('\\n eval dataset')\n",
        "print(ev_ds.isna().sum())\n",
        "print('\\n final eval dataset')\n",
        "print(f_ev_ds.isna().sum())"
      ],
      "metadata": {
        "id": "f4rMw4EXL1_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop all NaN values.\n",
        "f_ev_ds.dropna(inplace=True)\n",
        "tds.dropna(inplace=True)\n",
        "ev_ds.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "vXWad_xvU9OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training dataset')\n",
        "print(tds.isna().sum())\n",
        "print('\\n eval dataset')\n",
        "print(ev_ds.isna().sum())\n",
        "print('\\n final eval dataset')\n",
        "print(f_ev_ds.isna().sum())"
      ],
      "metadata": {
        "id": "o2L9iJoAU529"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tot_days = tds['datetime'].dt.date.nunique()\n",
        "print(f'the total amount of days in the dataset is: {tot_days}')\n",
        "# tot_speed = tds['SPEED_MS_AVG'].sum()\n",
        "# print(f'\\n The total avg_speed in m/s is : {tot_speed}')\n",
        "tot_flow = tds['FLOW'].sum()\n",
        "print(f'\\n the total flow of the dataset is:{tot_flow}')\n"
      ],
      "metadata": {
        "id": "8KMVeh3SQztX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We only find nan values in the flow category."
      ],
      "metadata": {
        "id": "T_Qxg8H6MIsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define what is congestion and what is not.\n",
        "# congestion_flow = tds[tds['FLOW'] < 100]\n",
        "# congestion_speed = tds[tds['SPEED_MS_AVG'] < 10]"
      ],
      "metadata": {
        "id": "oezW0AffMMBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering the dataset to only include the data within hours 04:00 and 06:00, this to get an accurate description of free flow speed.\n",
        "tds_offpeak = tds[(tds['datetime'].dt.time >= pd.to_datetime(\"04:00:00\").time()) &\n",
        "                (tds['datetime'].dt.time <= pd.to_datetime(\"06:00:00\").time())]\n",
        "\n",
        "#Ensuring we only get correctly read speeds. E.g Removing any negative speeds and random slow drivers\n",
        "#that do not actually depict the actual free flowspeed e.g people speeding and drinving super slow...\n",
        "tds_offpeak = tds_offpeak[(tds_offpeak['FLOW'] > 0) &\n",
        "                        (tds_offpeak['SPEED_MS_AVG'].between(5, 50))]\n",
        "\n",
        "# Calculating the free flow speed t\n",
        "# only take the observations in the 85th quantile [m/s]\n",
        "ffs_ms = (tds_offpeak['SPEED_MS_AVG'].quantile(0.85))\n",
        "# convert to km/h\n",
        "ffs_kmh = (ffs_ms * 3.6)\n",
        "print(f\"Free-flow speed (85th percentile): \\n Free flow speed: {ffs_ms} [m/s] \\n Free flow speed {ffs_kmh} [km/h]\")"
      ],
      "metadata": {
        "id": "Ou3DA0M5VJKf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}